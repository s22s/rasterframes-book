{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "In this example we will do some simple cell clustering based on multiband imagery in the region around Elkton, Virginia.\n",
    "\n",
    "## Setup \n",
    "\n",
    "First some setup. We import all the necessary libraries and create our `SparkSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrasterframes import *\n",
    "from pyrasterframes.rasterfunctions import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pathlib import Path\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    master(\"local[*]\"). \\\n",
    "    appName(\"RasterFrames\"). \\\n",
    "    config(\"spark.ui.enabled\", \"false\"). \\\n",
    "    getOrCreate(). \\\n",
    "    withRasterFrames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The first step is to load multiple bands of imagery and construct a single RasterFrame from them. To do this we:\n",
    "\n",
    "1. Identify the GeoTIFF filename.\n",
    "2. Read the TIFF raster\n",
    "3. Create the names of our columns\n",
    "4. Define a function for reading in a RasterFrame based on a band number\n",
    "5. Use the RasterFrames spatialJoin function to create a new RasterFrame with a column for each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_dir = Path('./samples').resolve()\n",
    "# Utility for reading imagery from our test data set\n",
    "filenamePattern = \"L8-B{}-Elkton-VA.tiff\"\n",
    "bandNumbers = range(1, 5)\n",
    "bandColNames = ['band_{}'.format(n) for n in bandNumbers]\n",
    "\n",
    "def readTiff(band):\n",
    "    return spark.read.geotiff(resource_dir.joinpath(filenamePattern.format(band)).as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "joinedRF = reduce(lambda rf1, rf2: rf1.asRF().spatialJoin(rf2.drop('bounds').drop('metadata')),\n",
    "                  [readTiff(b).withColumnRenamed('tile', 'band_{}'.format(b)) for b in bandNumbers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see a `spatial_key` column, `bounds`, `metadata`, and 4 columns of tiles, representing our four bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spatial_key: struct (nullable = false)\n",
      " |    |-- col: integer (nullable = false)\n",
      " |    |-- row: integer (nullable = false)\n",
      " |-- bounds: polygon (nullable = true)\n",
      " |-- metadata: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = false)\n",
      " |-- band_1: rf_tile (nullable = false)\n",
      " |-- band_2: rf_tile (nullable = false)\n",
      " |-- band_3: rf_tile (nullable = false)\n",
      " |-- band_4: rf_tile (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedRF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline \n",
    "\n",
    "PySparkML requires that each observation be in its own row, and those\n",
    "observations be packed into a single `Vector`. The first step is to\n",
    "\"explode\" the tiles into a single row per cell/pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploder = TileExploder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"vectorize\" the the band columns, as required by SparkML, we use the SparkML \n",
    "`VectorAssembler`. We then configure our algorithm, create the transformation pipeline,\n",
    "and train our model. (Note: the selected value of *K* below is arbitrary.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler() \\\n",
    "    .setInputCols(bandColNames) \\\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "# Configure our clustering algorithm\n",
    "k = 5\n",
    "kmeans = KMeans().setK(k)\n",
    "\n",
    "# Combine the three stages\n",
    "pipeline = Pipeline().setStages([exploder, assembler, kmeans])\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(joinedRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Once trained, the model can be saved off for later use, or used immediately on the same\n",
    "data we used to compute the model. First, we run the data through the model to compute \n",
    "cluster IDs for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+------------+---------+------+------+------+------+--------------------+----------+\n",
      "|spatial_key|              bounds|            metadata|column_index|row_index|band_1|band_2|band_3|band_4|            features|prediction|\n",
      "+-----------+--------------------+--------------------+------------+---------+------+------+------+------+--------------------+----------+\n",
      "|      [0,0]|POLYGON ((703986....|Map(AREA_OR_POINT...|           0|        0|9470.0|8491.0|7805.0|6697.0|[9470.0,8491.0,78...|         0|\n",
      "|      [0,0]|POLYGON ((703986....|Map(AREA_OR_POINT...|           1|        0|9566.0|8607.0|8046.0|6898.0|[9566.0,8607.0,80...|         0|\n",
      "|      [0,0]|POLYGON ((703986....|Map(AREA_OR_POINT...|           2|        0|9703.0|8808.0|8377.0|7222.0|[9703.0,8808.0,83...|         2|\n",
      "+-----------+--------------------+--------------------+------------+---------+------+------+------+------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustered = model.transform(joinedRF)\n",
    "clustered.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterResults = list(filter(lambda x: str(x).startswith('KMeans'), model.stages))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sum of squared distances of points to their nearest center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within set sum of squared errors: 10442521284.334034\n"
     ]
    }
   ],
   "source": [
    "metric = clusterResults.computeCost(clustered)\n",
    "print(\"Within set sum of squared errors: %s\" % metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "\n",
    "The predictions are in a DataFrame with each row representing a separate pixel. \n",
    "To assemble a raster to visualize the cluster assignments, we have to go through a\n",
    "multi-stage process to get the data back in tile form, and from there to combined\n",
    "raster form.\n",
    "\n",
    "First, we get the DataFrame back into RasterFrame form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spatial_key: struct (nullable = false)\n",
      " |    |-- col: integer (nullable = false)\n",
      " |    |-- row: integer (nullable = false)\n",
      " |-- prediction: rf_tile (nullable = true)\n",
      "\n",
      "+-----------+------------------------------------------------+\n",
      "|spatial_key|prediction                                      |\n",
      "+-----------+------------------------------------------------+\n",
      "|[0,0]      |ByteConstantNoDataArrayTile([B@3275ca1b,186,169)|\n",
      "+-----------+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tlm = joinedRF.tileLayerMetadata()\n",
    "layout = tlm['layoutDefinition']['tileLayout']\n",
    "\n",
    "retiled = clustered.groupBy('spatial_key').agg(\n",
    "    assembleTile('column_index', 'row_index', 'prediction',\n",
    "        layout['tileCols'], layout['tileRows'], 'int8')\n",
    ")\n",
    "\n",
    "rf = retiled.asRF('spatial_key', tlm)\n",
    "rf.printSchema()\n",
    "rf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To render our visualization, we convert to a raster first, which gives us a 1-D array with all the cell values. We then reshape the raster into a 2d array and use\n",
    "matplotlib colormap to assign each cluster a different color and then graph the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f872fd52048>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes a while\n",
    "import numpy as np\n",
    "raster = np.asarray(list(rf.toIntRaster('prediction', 186, 169)))\n",
    "\n",
    "pixels = np.reshape(raster, (169, 186))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.set_cmap('Accent')\n",
    "plt.imshow(pixels)\n",
    "fig.add_subplot(1, 2, 2)\n",
    "pixels2 = mpl.pyplot.imread(\"pics/L8-RGB-VA.png\")\n",
    "plt.imshow(pixels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colors in the first picture are just the colormap's representation of the clusters assigned by the model, which are ints between 0 and 4, inclusive. The picture on the right is an RGB image of the scene. As we can see, blue clusters appear to be small centers of intense urban activity. Brown clusters are urban activity, green corresponds closely to roads and pavement, gray appears to be farmland, and orange matches closely with forested regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
